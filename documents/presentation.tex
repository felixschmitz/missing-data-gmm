\documentclass[aspectratio=1610]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{bbm}
\usepackage[
    natbib=true,
    bibencoding=inputenc,
    bibstyle=authoryear-ibid,
    citestyle=authoryear-comp,
    maxcitenames=3,
    maxbibnames=10,
    useprefix=false,
    sortcites=true,
    backend=biber
]{biblatex}
\addbibresource{refs.bib}
\title{A GMM approach for dealing with missing data on regressors}
\subtitle{Dummy variable method, weak explanatory power and real world application}
\date{\today}
\author{Felix Schmitz}

\usetheme{UniBonn}

\begin{document}
\usebeamertemplate{custom equation spacing}

\begin{frame}[plain]
	\titlepage
\end{frame}

\begin{framecontent}
	\frametitle{Table of contents}
\end{framecontent}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Model Setup}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
    \frametitle{Model Setup (revisited)}
    \begin{itemize}
        \item<1-> Consider the \textbf{standard linear regression} model:

        \begin{equation}\label{eq:1}
            y_i = \alpha_0 x_i + z_i^{\prime} \beta_0 + \epsilon_i, \quad i= 1,\ldots,n \quad \text{where }  \mathbb{E}[x_i \epsilon_i] = 0, \mathbb{E}[z_i \epsilon_i] = 0
        \end{equation}

        \item<1-> $x_i$ is a (possibly missing) scalar regressor (\( m_i = \mathbbm{1}\{x_i \text{ missing}\} \)).
		\item<1-> $z_i$ contains an intercept and further instrument(s).
        \item<2-> As before, assume a \textbf{linear projection} of $x_i$ onto $z_i$:
        \begin{equation}\label{eq:2}
            x_i = z_i^{\prime} \gamma_0 + \xi_i \quad \text{ where } \mathbb{E}[z_i \xi_i] = 0
        \end{equation}

        \item<3-> $\gamma_0$ determines the strength of the relationship between $x_i$ and $z_i$.
        \item<3-> Plugging equation \eqref{eq:2} into \eqref{eq:1} yields:
        \begin{equation}\label{eq:3}
            y_i = z_i^{\prime} (\gamma_0 \alpha_0 + \beta_0) + \epsilon_i + \xi_i \alpha_0
        \end{equation}
		\item<4-> GMM will allow for overidentification tests to check the validity of the model
    \end{itemize}
	% complete-case with much higher standard errors for other covariates
	% as theoretically argued: not much difference in the coefficients and standard errors of x_i
	% overidentification test: \chi_2^2 distribution leads to p-values not rejectable on standard levels
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dummy Variable Method}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{Dummy Variable Method}
	\framesubtitle{$\ldots$ and resulting problems}
	\begin{itemize}
		\item<1-> saw complete data, linear imputation and GMM
		\item<2-> implementation of dummy variable method:
		\begin{itemize}
			\item<2-> replace missing data with $0$'s (or any other constant, e.g. $\bar{x}$)
			\item<2-> include dummy variable indicating missingness
		\end{itemize}
		\item<3-> down-sides:
		\begin{itemize}
			\item<3-> generally inconsistent method
			\item<3-> additional assumption of MCAR does not guarantee consistency
			\item<3-> consistency only guaranteed in implausible cases
			\item<3-> efficiency gains in comparison to complete data method not guaranteed
		\end{itemize}
		\item<4-> up-sides:
		\begin{itemize}
			\item<4-> easy to implement
			\item<4-> retain sample size
		\end{itemize}
		\item<5-> mentioned for educational purposes; not recommended for practical use
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Dummy Variable Method}
	\framesubtitle{$\ldots$ theoretical bias and inconsistency}
	\begin{itemize}
		\item<1-> Combining \eqref{eq:1} and adapted \eqref{eq:2} to imputed missing values:
		\begin{equation}\label{eq:4}
            y_i = \underbrace{(1-m_i) \alpha_0 x_i + z_i^{\prime} \beta_0}_{\substack{
				y_i \text{ from \eqref{eq:1} for}\\
				\text{non-missing } (m_i = 0)\\
				x_i \text{-values}}} +
				\underbrace{m_i z_i^{\prime} \gamma_0 \alpha_0}_{\substack{
					y_i \text{ correction from \eqref{eq:2}}\\
					\text{for missing } (m_i = 1)\\
					x_i \text{-values}}} +
				\underbrace{\epsilon_i}_{\substack{
					\text{error term}\\
					\text{from } \eqref{eq:1}}} +
				\underbrace{m_i \xi_i \alpha_0}_{\substack{
					\text{error term correction}\\
					\text{for imputations in \eqref{eq:2}}}}
		\end{equation}

		\item<2-> Separating components of $z_i$, $\gamma_0$ (intercept, $\gamma_{10}$; instrument $z_{2i}$, $\gamma_{20}$):
		\begin{equation}\label{eq:6}
			y_i = (1-m_i) \alpha_0 x_i + z_i^{\prime} \beta_0 + m_i \gamma_{10} \alpha_0 + m_i z_{2i}^{\prime} \gamma_{20} \alpha_0 + \epsilon_i + m_i \xi_i \alpha_0
		\end{equation}
		\item<3-> The dummy variable method is equivalent to running the regression in \eqref{eq:6} without including the regressors $m_i z_{2i}^{\prime}$
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Dummy Variable Method}
	\framesubtitle{$\ldots$ theoretical bias and inconsistency (continued)}
	\begin{itemize}
		\item<1-> The estimators $(\hat{\alpha}_{DM}, \hat{\beta}_{DM})^{\prime}$ are biased and inconsistent, unless
		\begin{enumerate}
			\item<2-> $\alpha_0 = 0$
			\begin{itemize}
				\item<2-> $x_i$ is an irrelevant variable in the regression \eqref{eq:1}
				\item<2-> drop $x_i$ from the regression to fix missing-data problem
			\end{itemize}
			\item<3-> $\gamma_{20} = 0$
			\begin{itemize}
				\item<3-> $z_{2i}$ is not useful under imputation model \eqref{eq:2} to predict $x_i$
				\item<3-> highly unlikely in practice
			\end{itemize}
		\end{enumerate}
		\item<4-> Further, efficiency gains from the dummy variable method are not guaranteed
		\item<4-> Next we are going to test the relevance of explanatory power via small values for $\alpha_0 \text{ and } \gamma_{20}$ in a MC setup
	\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Monte Carlo Analysis}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{Irrelevant variable with missing data}
	Under MCAR, homoskedasticity

	Design 2 is of high interest, as it lowers the relevance of the X's on the Y's in the large equation. That is, $\alpha_0$ is lower than in other cases. Do I need to add something regarding small gamma values here as well?

	$\alpha_0 = 0.1$
\end{frame}
\begin{frame}
    \input{../bld/tables/simulation_results_design2.tex}
\end{frame}

\begin{frame}
	\frametitle{Instrument with low explanatory power for imputation}
	$\gamma_{20}$ choose some small value
\end{frame}
\begin{frame}
    \input{../bld/tables/simulation_results_design2.tex}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Real World Application}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
	\frametitle{Real World Application}
	\framesubtitle{Wisconsin Longitudinal Study}
	\begin{itemize}
		\item<1-> Random sample of individuals who graduated from Wisconsin high schools in 1957

		\item<2-> $x_i$: BMI (body mass index) ratings based upon high-school yearbook photos
		\begin{itemize}
			\item<2-> independently assessed by raters; can be seen as proxy for (perceived) BMI in high school
			\item<2-> \textbf{not} MCAR, due to yearbook availability (missingness may covary with school identity)
			\item<2-> available for 888 of 3,969 men (22.4\%) and 1,107 of 4,276 women (25.9\%)
		\end{itemize}

		\item<3-> $z_{2i}$: IQ score (recorded in high school)

		\item<4-> $y_i$: years of education (determined in 1964)
	\end{itemize}
\end{frame}

\begin{frame}
	\frametitle{Real World Application}
	\center
    \includegraphics[width=0.9\textwidth]{../bld/tables/missreg_results.png}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
	\frametitle{Further Ideas}
	\begin{itemize}
		\item Testing the performance of GMM for different parameter setups (focus on $\alpha_0$ and $\gamma_{20}$)
		\item Applying the method to real-world panel datasets
		\item Using Wasserstein GANs to generate more nuanced missing data patterns
	\end{itemize}
\end{frame}

\end{document}

\printbibliography
